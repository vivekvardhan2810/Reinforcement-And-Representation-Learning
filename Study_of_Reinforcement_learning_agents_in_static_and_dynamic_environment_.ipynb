{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class GridWorld:\n",
        "    def __init__(self, shape):\n",
        "        self.shape = shape\n",
        "        self.obstacles = [(1, 1), (2, 2)]  # List of obstacle positions\n",
        "        self.goal = (2, 3)  # Goal position\n",
        "        self.agent = (0, 0)  # Agent's initial position\n",
        "\n",
        "    def reset(self):\n",
        "        self.agent = (0, 0)\n",
        "        return self.agent\n",
        "\n",
        "    def step(self, action):\n",
        "        moves = [(0, 1), (1, 0), (0, -1), (-1, 0)]  # Right, Down, Left, Up\n",
        "        new_pos = (self.agent[0] + moves[action][0], self.agent[1] + moves[action][1])\n",
        "\n",
        "        if new_pos[0] >= 0 and new_pos[0] < self.shape[0] \\\n",
        "           and new_pos[1] >= 0 and new_pos[1] < self.shape[1] \\\n",
        "           and new_pos not in self.obstacles:\n",
        "            self.agent = new_pos\n",
        "\n",
        "        if self.agent == self.goal:\n",
        "            reward = 1\n",
        "            done = True\n",
        "        else:\n",
        "            reward = 0\n",
        "            done = False\n",
        "\n",
        "        return self.agent, reward, done\n",
        "\n",
        "class QLearningAgent:\n",
        "    def __init__(self, num_actions, alpha=0.1, gamma=0.9, epsilon=0.1):\n",
        "        self.num_actions = num_actions\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.Q = {}\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        if np.random.uniform(0, 1) < self.epsilon:\n",
        "            return np.random.choice(self.num_actions)\n",
        "        else:\n",
        "            return np.argmax([self.Q.get((state, a), 0) for a in range(self.num_actions)])\n",
        "\n",
        "    def update_Q_value(self, state, action, next_state, reward):\n",
        "        max_next_Q = max([self.Q.get((next_state, a), 0) for a in range(self.num_actions)])\n",
        "        current_Q = self.Q.get((state, action), 0)\n",
        "        new_Q = current_Q + self.alpha * (reward + self.gamma * max_next_Q - current_Q)\n",
        "        self.Q[(state, action)] = new_Q\n",
        "\n",
        "def run_experiment(environment):\n",
        "    num_episodes = 1000\n",
        "    env = GridWorld((4, 4))\n",
        "    agent = QLearningAgent(4)\n",
        "\n",
        "    for _ in range(num_episodes):\n",
        "        state = env.reset()\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "            action = agent.choose_action(state)\n",
        "            next_state, reward, done = env.step(action)\n",
        "            agent.update_Q_value(state, action, next_state, reward)\n",
        "            state = next_state\n",
        "\n",
        "    return agent.Q\n",
        "\n",
        "static_Q_values = run_experiment(GridWorld((4, 4)))\n",
        "print(\"Static environment Q-values:\")\n",
        "print(static_Q_values)\n",
        "\n",
        "class DynamicGridWorld(GridWorld):\n",
        "    def __init__(self, shape):\n",
        "        super().__init__(shape)\n",
        "        self.moving_obstacle = (1, 3)  # Initial position of the moving obstacle\n",
        "\n",
        "    def step(self, action):\n",
        "        # Move the obstacle randomly\n",
        "        self.moving_obstacle = np.random.choice([(1, 2), (2, 3), (1, 3)])\n",
        "\n",
        "        # Agent's movement logic remains the same\n",
        "        return super().step(action)\n",
        "\n",
        "dynamic_Q_values = run_experiment(DynamicGridWorld((4, 4)))\n",
        "print(\"\\nDynamic environment Q-values:\")\n",
        "print(dynamic_Q_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCZfcqW_cST7",
        "outputId": "58566f9a-8692-461c-8cd0-d508415b6781"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Static environment Q-values:\n",
            "{((0, 0), 0): 0.6560999999999979, ((0, 1), 0): 0.7289999999999983, ((0, 2), 3): 0.6235151038632805, ((0, 2), 0): 0.8099999999999987, ((0, 3), 0): 0.7256546050168583, ((0, 3), 2): 0.6588508624327397, ((0, 3), 3): 0.7519017360186914, ((0, 3), 1): 0.899999999999999, ((1, 3), 0): 0.82807511138066, ((1, 3), 1): 0.9999999999999996, ((0, 0), 2): 0.5509307835269304, ((0, 1), 2): 0.5639623535137005, ((0, 0), 1): 0.3641106741962231, ((1, 0), 0): 0.0, ((1, 0), 2): 0.0, ((1, 0), 1): 0.0, ((2, 0), 0): 0.0, ((2, 1), 2): 0.0, ((2, 1), 1): 0.0, ((3, 1), 0): 0.0008100000000000002, ((3, 2), 0): 0.025200000000000004, ((3, 3), 0): 0.0, ((3, 3), 1): 0.0, ((3, 3), 3): 0.271, ((1, 0), 3): 0.5324734100868916, ((0, 2), 2): 0.6061674441867534, ((1, 3), 3): 0.727440608577938, ((0, 1), 1): 0.6222698295064646, ((0, 2), 1): 0.6928968314407693, ((1, 2), 0): 0.8958033291733596, ((0, 0), 3): 0.5493236918212985, ((0, 1), 3): 0.6118172731722019, ((1, 3), 2): 0.7219332731036018, ((1, 2), 2): 0.015099767327042938, ((2, 1), 0): 0.0, ((1, 2), 3): 0.1385099999999998, ((2, 1), 3): 0.0}\n",
            "\n",
            "Dynamic environment Q-values:\n",
            "{((0, 0), 0): 0.6560999999999979, ((0, 1), 0): 0.7289999999999983, ((0, 2), 0): 0.8099999999999987, ((0, 3), 0): 0.7719132726282448, ((0, 3), 2): 0.648528059179395, ((0, 3), 3): 0.7781212554683554, ((0, 3), 1): 0.899999999999999, ((1, 3), 0): 0.7915849715025782, ((1, 3), 3): 0.7590563716037004, ((1, 3), 2): 0.7182937442941063, ((1, 2), 0): 0.8930765070552854, ((1, 3), 1): 0.9999999999999996, ((0, 0), 3): 0.5567910267968058, ((0, 2), 3): 0.6775951388987838, ((0, 0), 1): 0.4863000531490978, ((1, 0), 0): 0.0, ((1, 0), 2): 0.011659186899856844, ((1, 0), 1): 0.0025679570268897353, ((2, 0), 0): 0.0, ((2, 1), 3): 0.0, ((2, 1), 0): 0.0, ((2, 1), 2): 0.0, ((2, 0), 3): 0.061817027993202975, ((1, 0), 3): 0.581141555617636, ((0, 1), 3): 0.6346100492686896, ((0, 1), 1): 0.6143749078123062, ((0, 0), 2): 0.5685660100812099, ((0, 2), 2): 0.5737751937200386, ((0, 2), 1): 0.614159856284063, ((0, 1), 2): 0.5478606668387953, ((1, 2), 1): 0.07530524472973027, ((1, 2), 3): 0.0728999999999999}\n"
          ]
        }
      ]
    }
  ]
}