{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "\n",
        "# Initialize the Taxi-v3 environment\n",
        "env = gym.make('Taxi-v3')\n",
        "\n",
        "# Set the number of episodes for training\n",
        "num_episodes = 10000\n",
        "\n",
        "# Set the learning rate\n",
        "alpha = 0.85\n",
        "\n",
        "# Set the discount factor\n",
        "gamma = 0.95\n",
        "\n",
        "# Initialize the Q-table with zeros\n",
        "Q = np.zeros([env.observation_space.n, env.action_space.n])\n",
        "\n",
        "# Set the number of episodes for exploration\n",
        "num_exploration_episodes = 1000\n",
        "\n",
        "# Set the exploration rate\n",
        "epsilon = 1.0\n",
        "\n",
        "# Set the exploration decay rate\n",
        "decay_rate = 0.001\n",
        "\n",
        "# Set the minimum exploration rate\n",
        "min_epsilon = 0.01\n",
        "\n",
        "# Training loop\n",
        "for episode in range(num_episodes):\n",
        "\n",
        "    # Reset the environment\n",
        "    state = env.reset()\n",
        "\n",
        "    # Set the exploration rate for this episode\n",
        "    if episode < num_exploration_episodes:\n",
        "        epsilon = 1.0\n",
        "    else:\n",
        "        epsilon = min_epsilon + (1.0 - min_epsilon) * np.exp(-decay_rate * (episode - num_exploration_episodes))\n",
        "\n",
        "    # Set the exploration flag\n",
        "    exploration = np.random.uniform(0, 1) < epsilon\n",
        "\n",
        "    # Training loop\n",
        "    for step in range(1000):\n",
        "\n",
        "        # Choose an action based on the exploration flag\n",
        "        if exploration:\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "            action = np.argmax(Q[state])\n",
        "\n",
        "        # Take the action and get the next state and reward\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "\n",
        "        # Update the Q-table\n",
        "        Q[state, action] = (1 - alpha) * Q[state, action] + alpha * (reward + gamma * np.max(Q[next_state]))\n",
        "\n",
        "        # Update the state\n",
        "        state = next_state\n",
        "\n",
        "        # Check if the episode is done\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "# Print the final Q-table\n",
        "print(Q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5btzMA41YP3t",
        "outputId": "50cd5b16-0dbb-44f9-8606-c9afa31c3ce5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.          0.          0.          0.          0.          0.        ]\n",
            " [ 2.75200369  3.94947757  2.75200369  3.94947757  5.20997639 -5.05052243]\n",
            " [ 7.93349184  9.40367562  7.93349184  9.40367562 10.9512375   0.40367562]\n",
            " ...\n",
            " [10.9512375  12.58025    10.9512375   9.40367562  1.9512375   1.9512375 ]\n",
            " [ 5.20997639  6.53681725  5.20997639  6.53681725 -3.79002361 -3.79002361]\n",
            " [16.1        14.295      16.1        18.          7.1         7.1       ]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}